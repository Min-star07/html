<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>CSS Inclusion Example</title>

    <!-- External CSS -->
    <style>
      body {
        font-family: Arial, sans-serif;
        margin: 20px;
        line-height: 1.6;
        max-width: 800px;
      }
      h1 {
        color: #333;
      }
      h2 {
        border-bottom: 2px solid #007bff;
        color: #007bff;
        padding-bottom: 5px;
      }
      p {
        margin: 15px 0;
      }
      pre {
        background-color: #f4f4f4;
        padding: 10px;
        border-radius: 5px;
        overflow-x: auto;
      }
      code {
        font-family: Consolas, "Courier New", monospace;
        background-color: #f4f4f4;
        padding: 2px 4px;
        border-radius: 3px;
      }
      blockquote {
        border-left: 5px solid #ccc;
        padding-left: 10px;
        margin: 20px 0;
        color: #050505;
        font-style: italic;
      }
      .note {
        background-color: #e7f3fe;
        border-left: 5px solid #2196f3;
        padding: 10px;
        margin: 20px 0;
      }
      .image-container {
        text-align: center;
        margin: 20px 0;
      }
      .image-container img {
        max-width: 100%;
        height: auto;
        border: 1px solid #ccc;
        border-radius: 5px;
      }
      .back-to-outline {
        margin-top: 30px;
        text-align: center;
      }
      a {
        text-decoration: none;
        color: #007bff;
      }
      a:hover {
        text-decoration: underline;
      }
    </style>
  </head>
  <body>
    <!-- Header Section -->
    <div class="header">
      <h2>The Introduction of ResNet</h2>
    </div>

    <!-- Content Section -->
    <div class="content">
      <h3>A pretrained network that recognizes the subject of an image</h3>
      <pre><code>from torchvision import models 
dir(models)  # To show the pretrained model of pytorch</code></pre>
      <pre><code>alexnet = models.AlexNet()
resnet = models.resnet101(pretrained=True)
resnet</code></pre>
      <p>
        Use the resnet to recognize image, the number 101 is the layer numbers,
        pretrained=True that means when you loads model, the weights is also
        downloaded from training on a larger dataset.
      </p>

      <pre><code>from torchvision import transforms

preprocess = transforms.Compose(
    [
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=(0.229, 0.224, 0.225)),
    ]
)</code></pre>

      <p>
        Compose is a series of operations that make input meet the requirements
        of model, such as Resize, CenterCrop, ToTensor, and Normalize.
      </p>

      <pre><code>from PIL import Image

img = Image.open("../pytorch_dlwpt-code-master/data/p1ch2/bobby.jpg")
# Display the image properties
print(f"Format: {img.format}")  # Image format (e.g., JPEG, PNG)
print(f"Size: {img.size}")  # Image size (width, height)
print(f"Mode: {img.mode}")  # Image mode (e.g., RGB, L, RGBA)
print(f"Color Palette: {img.palette}")  # Color palette, if applicable
print(f"Info: {img.info}")

# Transforms into Tensor
img_t = preprocess(img)
# Display the tensor properties
print(f"Shape: {img_t.shape}")  # Shape of the tensor (channels, height, width)
print(f"Dtype: {img_t.dtype}")  # Data type of the tensor elements
print(f"Device: {img_t.device}")  # Device where the tensor is stored (e.g., CPU, GPU)
print(f"Min value: {img_t.min().item()}")  # Minimum value in the tensor
print(f"Max value: {img_t.max().item()}")  # Maximum value in the tensor
print(f"Mean value: {img_t.mean().item()}")  # Mean value of the tensor
print(img_t)</code></pre>

      <p>The style of PIL to read picture and see the properties.</p>

      <!-- Citation for the GitHub Jupyter Notebook -->
      <div class="note">
        <h3>Additional Resource</h3>
        <p>
          Smith, A. (2024).
          <a
            href="https://github.com/Min-star07/ML/blob/master/lesson9/p1ch2_pretrained_networks.ipynb"
            target="_blank"
            >example_notebook.ipynb</a
          >. In <em>ExampleRepo</em>. GitHub. Accessed 24 Sept. 2024.
        </p>
      </div>
    </div>
  </body>
</html>
